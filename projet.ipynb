{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning for NLP - Project 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries and global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\tboug\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\tboug\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg bm25= 0.8135524489389909\n"
     ]
    }
   ],
   "source": [
    "from BM25 import loadNFCorpus, text2TokenList, run_bm25_only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(common_texts)]\n",
    "\n",
    "# model = Doc2Vec(documents, vector_size=5, window=2, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg bm25= 0.8135524489389909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8135524489389909"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run_bm25_only(0,150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg bm25= 0.46335714418774215\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.46335714418774215"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run_bm25_only(0,3192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessing as prepro\n",
    "import models\n",
    "from metrics import ndcgAt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alkylphenols', 'human', 'milk', 'relations', 'dietary', 'habits', 'central', 'taiwan', 'pubmed', 'ncbi', 'abstract', 'aims', 'study', 'determine', 'concentrations', 'num', 'nonylphenol', 'num', 'octylphenol', 'num', 'human', 'milk', 'samples', 'examine', 'related', 'factors', 'including', 'mothers', 'demographics', 'dietary', 'habits', 'women', 'consumed', 'median', 'amount', 'cooking', 'oil', 'significantly', 'higher', 'concentrations', 'num', 'ng/g', 'consumed', 'num', 'ng/g', 'num', 'concentration', 'significantly', 'consumption', 'cooking', 'oil', 'beta', 'num', 'num', 'fish', 'oil', 'capsules', 'beta', 'num', 'num', 'adjustment', 'age', 'body', 'mass', 'index', 'bmi', 'concentration', 'significantly', 'consumption', 'fish', 'oil', 'capsules', 'beta', 'num', 'num', 'processed', 'fish', 'products', 'beta', 'num', 'num', 'food', 'pattern', 'cooking', 'oil', 'processed', 'meat', 'products', 'factor', 'analysis', 'strongly', 'concentration', 'human', 'milk', 'num', 'determinations', 'aid', 'suggesting', 'foods', 'consumption', 'nursing', 'mothers', 'order', 'protect', 'infants', 'np/op', 'exposure', 'num', 'elsevier', 'rights', 'reserved']\n"
     ]
    }
   ],
   "source": [
    "dicDoc, dicReq, dicReqDoc = prepro.load_data()\n",
    "corpus = prepro.build_corpus(dicDoc)\n",
    "print(corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "docsToKeep,reqsToKeep,dicTrueResults,corpusDocTokenList,corpusDocTokenDic,corpusDocName,corpusDicoDocName,corpusReqName,corpusReqTokenList,corpusReqTokenDic,corpusDicoReqName = prepro.tokenize(dicDoc,dicReq,dicReqDoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w2v = models.model_word2vec(corpusDocTokenDic,corpusReqTokenDic,corpusDocTokenList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_pred = models.model_bm25(corpusDocTokenList,corpusReqTokenDic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w2v_pred = models.model_word2vec_scores_to_list(w2v,corpusDicoDocName)\n",
    "# ndcgAt5(w2v_pred,dicTrueResults,corpusDicoDocName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4119320534082562"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcgAt5(bm25_pred,dicTrueResults,corpusDicoDocName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bm25_pred_top = models.top_results(bm25_pred,corpusDicoDocName) # Top 10 for the moment\n",
    "# combination_pred = models.model_word2vec_second(bm25_pred_top,corpusDicoDocName,corpusDocTokenDic,corpus)\n",
    "# ndcgAt5(combination_pred,dicTrueResults,corpusDicoDocName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010332556191092048"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25_pred_top = models.top_results(bm25_pred,corpusDicoDocName) # Top 10 for the moment\n",
    "combination_pred = models.model_bioModel_second(bm25_pred_top,corpusDicoDocName,corpusDocTokenDic,corpus)\n",
    "ndcgAt5(combination_pred,dicTrueResults,corpusDicoDocName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "results = bm25_pred_top\n",
    "\n",
    "model_wordScale = models.model_load_bioModel()\n",
    "\n",
    "model = {}\n",
    "\n",
    "# Dictionnary with inverted keys and values of corpusDicoDocName\n",
    "doc_from_position = {}\n",
    "for k,v in corpusDicoDocName.items():\n",
    "    doc_from_position[v] = k\n",
    "\n",
    "# Get the docs with top results in previous model\n",
    "for req in results:\n",
    "    positions = []\n",
    "    docs_to_evaluate = []\n",
    "    for i in results[req]:\n",
    "        if i > 0:\n",
    "            positions.append(list(results[req]).index(i))\n",
    "            docs_to_evaluate.append(doc_from_position[list(results[req]).index(i)])\n",
    "\n",
    "    # Vectorize each one of those doc\n",
    "    docs_to_evaluate_vectorized = []\n",
    "    for doc in docs_to_evaluate:\n",
    "        doc_content = corpusDocTokenDic[doc]\n",
    "        docs_to_evaluate_vectorized.append(models.model_word2vec_textScale(doc_content,model_wordScale,200))\n",
    "\n",
    "    req_vectorized = models.model_word2vec_textScale(req,model_wordScale)\n",
    "\n",
    "    docs_evaluated = []\n",
    "    for doc in docs_to_evaluate_vectorized:\n",
    "        docs_evaluated.append(models.cosine_similarity(req_vectorized,doc))\n",
    "\n",
    "    # Re-fill result with 0 for other documents\n",
    "    res = np.zeros(len(corpusDicoDocName))\n",
    "    for j in range(len(docs_evaluated)):\n",
    "        res[positions[j]] = docs_evaluated[j]\n",
    "\n",
    "    model[req] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0,\n",
       " 603.2069307608075,\n",
       " 615.0656401893605,\n",
       " 615.4491765266109,\n",
       " 635.2094864381188,\n",
       " 692.7932885492166,\n",
       " 790.0560600475912,\n",
       " 812.0834757801621,\n",
       " 901.2513516640765,\n",
       " 947.4604122579915,\n",
       " 1258.4378073037105}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(bm25_pred_top['PLAIN-1'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
